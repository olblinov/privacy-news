---
title: 14 US attorney generals sue TikTok for COPPA violations
tags:
  - us
  - adtech
links:
  - https://oag.ca.gov/news/press-releases/attorney-general-bonta-attorney-general-james-lead-coalition-suing-tiktok
---
California Attorney General Rob Bonta and New York Attorney General Letitia James today co-led a bipartisan coalition of 14 attorneys general in filing separate enforcement actions against TikTok for violations of state consumer protection laws.

“Our investigation has revealed that TikTok cultivates social media addiction to boost corporate profits. TikTok intentionally targets children because they know kids do not yet have the defenses or capacity to create healthy boundaries around addictive content,” **said Attorney General Rob Bonta.** “When we look at the youth mental health crisis and the revenue machine TikTok has created, fueled by the time and attention of our young people, it’s devastatingly obvious: Our children and teens never stood a chance against these social media behemoths. TikTok must be held accountable for the harms it created in taking away the time — and childhoods — of American children.”

“Young people are struggling with their mental health because of addictive social media platforms like TikTok,” **said** **New York** **Attorney General Letitia James**. “TikTok claims that their platform is safe for young people, but that is far from true. In New York and across the country, young people have died or gotten injured doing dangerous TikTok challenges and many more are feeling more sad, anxious, and depressed because of TikTok’s addictive features. Today, we are suing TikTok to protect young people and help combat the nationwide youth mental health crisis. Kids and families across the country are desperate for help to address this crisis, and we are doing everything in our power to protect them.”

TikTok’s misconduct includes: 

- **Deploying a content-recommendation system designed to be addictive in order to maximize the time young users spend on the platform.** TikTok’s algorithmic features are designed to keep minors on the platform as long as possible and as often as possible, despite the dangers of compulsive use.
- **Using manipulative features to addict young users and maximize their time on its platform.** These features exploit children's psychological vulnerabilities and are deployed to keep kids and teens on the platform for longer.
	- _BEAUTY FILTERS_ Beauty filters and effects are deeply harmful to young users; they foster unrealistic beauty standards, harm self-esteem, and can induce negative body image issues and related physical and mental disorders. TikTok knows these filters and effects significantly increase platform use, particularly among young users, and retains these features despite their harms.
	- _AUTOPLAY_. To manipulate users into compulsively spending more time on the platform, TikTok does not allow them to disable Autoplay. TikTok uses Autoplay to continuously play new and temporary posts; this exploits young users’ novelty-seeking minds and eliminates their autonomy to choose to stop.
	- _ENDLESS/INFINITE SCROLL_. Endless scrolling compels young users to spend more time on the platform by making it difficult to disengage. It strips away a natural stopping point or opportunity to turn to a new activity and distorts users’ perception of time.
	- _TIKTOK STORIES AND TIKTOK LIVE_. Content on these features is only available temporarily — users must tune in immediately or lose the opportunity to interact. These time-sensitive features are designed to encourage young users to compulsively return to the platform by exploiting their uniquely sensitive fear of missing out. 
	- _PUSH NOTIFICATIONS_. Push notifications unfairly entice young users by overloading and overwhelming them to return to the platform. Some pushes are designed to keep young users from quitting the platform altogether, and others encourage young users to open the application. TikTok has even used fake notifications to manipulate users into opening its platform. 
	- _LIKES AND COMMENTS_. At key development states it can be overwhelmingly important for children and teens to be accepted by their peers. TikTok’s design and display of highlighting “likes” as a form of social validation has an especially powerful effect on young users and can neurologically alter teenagers’ perception of online posts, in addition to driving compulsive use.
- **Engaging in a scheme that deceptively markets the platform and platform features as promoting young users’ safety and well-being.** TikTok employs a coordinated array of features, tools, content moderation efforts, community guidelines, and public assurances intended to promote a public narrative that the platform is appropriate and safe for young users and that TikTok prioritizes user safety. In truth, such features and efforts do not work as advertised, the harmful effects of the platform are far greater than acknowledged, and TikTok does not prioritize safety over profit.
- **Exploiting children’s data without parental notice or consent.** Despite knowing certain users are under 13 years old and despite the platform being directed toward children, TikTok has collected and used personal information from children's accounts without parental consent or notice. Doing so is both unfair and fails to satisfy TikTok’s obligations under federal law.